{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import socket\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def send_data_over_socket(file_path, host='localhost', port=9999, chunk_size=2):\n",
    "#     s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "#     s.bind((host, port))\n",
    "#     s.listen(1)\n",
    "#     print(f\"Listening for connections on {host}:{port}\")\n",
    "    \n",
    "#     conn, addr = s.accept()\n",
    "#     print(f\"Connection from {addr}\")\n",
    "    \n",
    "#     last_sent_index = 0\n",
    "#     try:\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             # skip the lines that were already sent\n",
    "#             for _ in range(last_sent_index):\n",
    "#                 next(file)\n",
    "            \n",
    "#             records = []\n",
    "#             for line in file:\n",
    "#                 records.append(json.loads(line))\n",
    "#                 if len(records) == chunk_size:\n",
    "#                     chunk = pd.Dataframe(records)\n",
    "#                     print(chunk)\n",
    "#                     for record in chunk.to_dict(orient='records'):\n",
    "#                         serialize_data = json.dumps(record).encode('utf-8')\n",
    "#                         conn.send(serialize_data + b'\\n')\n",
    "#                         time.sleep(5)\n",
    "#                         last_sent_index += 1\n",
    "                    \n",
    "#                     records = []\n",
    "#     except (BrokenPipeError, ConnectionResetError):\n",
    "#         print('Client disconnected.')\n",
    "#     finally:\n",
    "#         conn.close()\n",
    "#         print('Connection closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send_data_over_socket('datasets/yelp_academic_dataset_review.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# from config.config import config\n",
    "\n",
    "# comment = 'Your food is ... i do not know. maybe not good and not bad at the same'\n",
    "\n",
    "# openai.api_key = config['openai']['api_key']\n",
    "# completion = openai.ChatCompletion.create(\n",
    "#     model='gpt-3.5-turbo-1106',\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": f\"\"\"\n",
    "#                 You're a machine learning model with a task of classifying comments into POSITIVE, NEGATIVE, NEUTRAL.\n",
    "#                 You are to respond with one word from the option specified above, do not add anything else.\n",
    "#                 Here is the comment: {comment}\n",
    "#             \"\"\"\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "# completion.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark_conn = SparkSession.builder.appName(\"SocketStreamConsumer\").getOrCreate()\n",
    "\n",
    "def start_streaming(spark):\n",
    "    try:\n",
    "        stream_df = (spark.readStream.format(\"socket\")\n",
    "                .option(\"host\", \"localhost\")\n",
    "                .option(\"port\", 9999)\n",
    "                .load()\n",
    "                )\n",
    "\n",
    "        schema = StructType([\n",
    "            StructField(\"review_id\", StringType()),\n",
    "            StructField(\"user_id\", StringType()),\n",
    "            StructField(\"business_id\", StringType()),\n",
    "            StructField(\"stars\", FloatType()),\n",
    "            StructField(\"date\", StringType()),\n",
    "            StructField(\"text\", StringType())\n",
    "        ])\n",
    "\n",
    "        stream_df = stream_df.select(from_json(col('value'), schema).alias(\"data\")).select((\"data.*\"))\n",
    "\n",
    "        query = stream_df.writeStream.outputMode(\"append\").format(\"console\").start()\n",
    "        query.awaitTermination()\n",
    "        # sentiment_analysis_udf = udf(sentiment_analysis, StringType())\n",
    "\n",
    "        # stream_df = stream_df.withColumn('feedback',\n",
    "        #                                     when(col('text').isNotNull(), sentiment_analysis_udf(col('text')))\n",
    "        #                                     .otherwise(None)\n",
    "        #                                     )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "start_streaming(spark_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
